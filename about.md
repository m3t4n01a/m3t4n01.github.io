---
layout: default
---

## About me - story

<img class="profile-picture" src="me_scaled.jpg">

I had first contact with AI/ML in my Master, in The Netherlands, which I did under the supervision of my now good friend [Marco Wiering](http://www.ai.rug.nl/~mwiering/). I am grateful to him for sharing his vast knowledge and enthusiasm as well as his positive vibes. See my Master thesis [here](Thesis_Adrian_Millea.pdf).

In my PhD, my previous supervisor was [Marc Deisenroth](https://sites.google.com/view/marcdeisenroth). Under him, I have worked on **variational inference**, which I found very interesting and useful. I learned a lot with Marc, he helped me a great deal, but I felt this was not the way for me to continue.

After that I studied **information geometry**, which I found extremely interesting, but that turned out to be a much harder and longer task than I initially had believed/hoped. However I did learn a lot in the process.

I finally settled on **deep reinforcement learning** as the main topic for my thesis, but soon I realized that many of the papers that came out were really just incremental results and very few actually brought real contributions to the field. I think this is generally valid for any rapidly developing field of science, as they are most affected by the illness/frenzy of publishing as many papers as possible. Luckily, I was not forced to publish (however I had to present some internal documents at Imperial, that would ideally turn into publications). In this process I also kind of developed a resentment towards publishing and felt that I wanted to publish important stuff, not just anything for the sake of publishing.

So then I decided I am going to do something which I truly believe in. Work to discover traits of general AI, or strong AI. So I started reading a lot of papers and books from neuroscience, psychology, cognitive science to learn about memory, decision making, consciousness, etc. I soon discovered a simple principle that can be applied hierarchically and to all types of memory, be it semantic, episodic, temporal, etc. I call it the neighbouring principle, you can read more about it [here](Efficient hierarchical subgoal discovery - draft.pdf). I also wrote a document describing how I see things and what I am doing, you can check it out [here](early_alpha.pdf).

Soon enough some interesting papers appeared, showing me that I am on the right path:

[1] Big-Loop Recurrence within the Hippocampal System Supports Integration of Information across Episodes. See [here](https://www.ncbi.nlm.nih.gov/pubmed/30236285).

[2] Navigating cognition: Spatial codes for human thinking. See [here](http://science.sciencemag.org/content/362/6415/eaat6766).

I also strongly believe that *ML should be available to all* not only the few, so I am working on a project which exposes ML to the any person, not only computer scientists, similar to [Orange](https://orange.biolab.si/). 

